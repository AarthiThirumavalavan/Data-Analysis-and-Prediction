# -*- coding: utf-8 -*-
"""Assignment_Aarthi_Thirumavalavan.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hMNMmunDzfLmbgZRUi2rkSQSIHvgriQd

Contents: 

---




*   Imports
*   Reading Input Data
*   Data Pre-processing
*   Essential Functions
*   Train-test split for model input
*   Model design - Baseline
*   SMOTE AND SMOTETOMEK sampling strategy on classifiers
*   One vs Rest dataset split on Classifiers
*   Best Model - Catboost with SMOTE sampling strategy and One-vs-Rest dataset split

# Imports
"""

import pandas as pd
import numpy as np
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from sklearn.metrics import matthews_corrcoef as mcc
from sklearn.metrics import roc_auc_score
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from imblearn.over_sampling import SMOTE
from imblearn.combine import SMOTETomek
!pip install catboost
import catboost
import matplotlib.pyplot as plt
import lightgbm as lgb
import warnings
warnings.filterwarnings('ignore')
from sklearn.preprocessing import MinMaxScaler
from sklearn.preprocessing import StandardScaler

from google.colab import drive
drive.mount('/content/drive')

"""# Reading input data"""

df_main = pd.read_csv('/content/drive/MyDrive/Micron/Q1_data.csv')
df = df_main.copy()

df.shape

"""# Data Pre-processing"""

#To check for duplicate values
df.drop_duplicates(keep="first",inplace=True)

df.shape #proves no duplicate rows are present

df.info()

#To check for null values
df.isnull().any().value_counts()

df.fillna(method="ffill",inplace=True)

df['target'].value_counts()

#Target distribution in dataset
df['target'].value_counts(normalize=True).plot(kind="bar")

#Distribution of float and int datatypes in the dataset
df.dtypes.value_counts()

"""**Normalization and Standardization of dataset**"""

#Normalization of dataset
norm = MinMaxScaler().fit_transform(df.drop('target',axis=1).values)
pd.DataFrame(norm)

#Data Standardization
sc = StandardScaler()
std = sc.fit_transform(norm)
std

X_nstd = pd.DataFrame(std)
X = pd.concat([X_nstd, df_main['target']],axis=1)
X

"""# Essential Functions"""

#Splitting dataset to form validation set
def split(df):
  x_train, x_val, y_train, y_val = train_test_split(df.drop(['target'], axis=1), \
                                                  df['target'].astype('int'),
                                                    test_size=0.20,shuffle=True,
                                                    random_state=0,
                                                    stratify=df['target'])
  return x_train, x_val, y_train, y_val

#Prediction report
from sklearn.metrics import matthews_corrcoef
def evaluate_model(y_true, y_pred, index_values):
  print('Classification report')
  print('-'*75)
  print(classification_report(y_true,y_pred))
  print('Confusion matrix')
  print('-'*75)
  cm = confusion_matrix(y_true, y_pred)
  cm_df = pd.DataFrame(cm.T, index=index_values, columns=index_values)
  cm_df.index.name = 'Predicted'
  cm_df.columns.name = 'True'
  print(cm_df)
  print('')
  print('Matthew Correlation coefficient')
  print('-'*75)
  print( matthews_corrcoef(y_true, y_pred))

#Over sampling and under sampling
def sampling_strategy(kind = "SMOTETOMEK"):
  if(kind == "SMOTE"):
    oversample = SMOTE(random_state=42)
    X, y = oversample.fit_resample(x_train, y_train)
  else:
    smt = SMOTETomek(random_state=42)
    X, y = smt.fit_resample(x_train, y_train)
  
  return X,y

"""# Train-test split for model input"""

#Class-wise distribution of target field
x_train, x_test, y_train, y_test = split(X)
train = pd.concat([x_train,y_train],axis=1)
test = pd.concat([x_test, y_test],axis=1)
print("Train dataset")
print(train['target'].value_counts())
print("Test dataset")
print(test['target'].value_counts())

"""# Model design - Baseline

**(a) LGBM Classifier**
"""

model1 = lgb.LGBMClassifier(random_state=0, n_estimators=500, 
                           learning_rate=0.1, num_leaves=31,
                           is_unbalance=True)

index_values = list(train.sort_values(by="target")['target'].unique())
x_train, x_val, y_train, y_val = split(train)

model1.fit(x_train, y_train, eval_set=(x_val,y_val), verbose=0)
val_pred = model1.predict(x_val)

evaluate_model(y_val, val_pred, index_values)

"""**(b) Random Forest Classifier**"""

model2 = RandomForestClassifier(max_depth=2, random_state=0)

index_values = list(train.sort_values(by="target")['target'].unique())
x_train, x_val, y_train, y_val = split(train)

model2.fit(x_train, y_train)
val_pred = model2.predict(x_val)

evaluate_model(y_val, val_pred, index_values)

"""**(c) Catboost Classifier**"""

model3 = catboost.CatBoostClassifier(n_estimators=2500,random_state=0, learning_rate=0.03, verbose=100, early_stopping_rounds=50,auto_class_weights="Balanced")

index_values = list(train.sort_values(by="target")['target'].unique())
x_train, x_val, y_train, y_val = split(train)

model3.fit(x_train, y_train)
val_pred = model3.predict(x_val)

evaluate_model(y_val, val_pred, index_values)

"""# SMOTE AND SMOTETOMEK sampling strategy on classifiers

**(a) On LGBM classifier**

(i) SMOTE sampling strategy
"""

index_values = list(train.sort_values(by="target")['target'].unique())
x_train, x_val, y_train, y_val = split(train)

X,y = sampling_strategy("SMOTE")
model1.fit(X, y, eval_set=(x_val,y_val), verbose=0)
val_pred = model1.predict(x_val)

evaluate_model(y_val, val_pred, index_values)

"""(ii) SMOTETOMEK sampling strategy"""

index_values = list(train.sort_values(by="target")['target'].unique())
x_train, x_val, y_train, y_val = split(train)

X,y = sampling_strategy("SMOTETOMEK")
model1.fit(X, y, eval_set=(x_val,y_val), verbose=0)
val_pred = model1.predict(x_val)

evaluate_model(y_val, val_pred, index_values)

"""**(b) Random Forest Classifier**

(i) SMOTE sampling strategy
"""

index_values = list(train.sort_values(by="target")['target'].unique())
x_train, x_val, y_train, y_val = split(train)

X,y = sampling_strategy("SMOTE")
model2.fit(X, y)
val_pred = model2.predict(x_val)

evaluate_model(y_val, val_pred, index_values)

"""(ii) SMOTETOMEK sampling strategy"""

index_values = list(train.sort_values(by="target")['target'].unique())
x_train, x_val, y_train, y_val = split(train)

X,y = sampling_strategy("SMOTETOMEK")
model2.fit(X, y)
val_pred = model2.predict(x_val)

evaluate_model(y_val, val_pred, index_values)

"""**(c) Catboost classifier**

(i) SMOTE sampling strategy
"""

index_values = list(train.sort_values(by="target")['target'].unique())
x_train, x_val, y_train, y_val = split(train)

X,y = sampling_strategy("SMOTE")
model3.fit(X, y, eval_set=(x_val,y_val), verbose=0)
val_pred = model3.predict(x_val)

evaluate_model(y_val, val_pred, index_values)

"""(ii) SMOTETOMEK sampling strategy"""

index_values = list(train.sort_values(by="target")['target'].unique())
x_train, x_val, y_train, y_val = split(train)

X,y = sampling_strategy("SMOTETOMEK")
model3.fit(X, y, eval_set=(x_val,y_val), verbose=0)
val_pred = model3.predict(x_val)

evaluate_model(y_val, val_pred, index_values)

"""# One vs Rest dataset split on Classifiers

**(a) LGBM Classifier-  SMOTE sampling strategy**
"""

onevsrest = train.copy()
model1 = lgb.LGBMClassifier(class_weight="balanced")
onevsrest['target'] = np.where(train['target'] == 0, 0, 999)
x_train, x_val, y_train, y_val = split(onevsrest)
index_values = list(onevsrest['target'].unique())

X, y = sampling_strategy("SMOTE")

model1.fit(X, y, eval_set=(x_val,y_val), verbose=0)
val_pred = model1.predict(x_val)
evaluate_model(y_val, val_pred, index_values)

model_1 = lgb.LGBMClassifier(random_state=0, n_estimators=500, 
                           learning_rate=0.1, num_leaves=31,
                           is_unbalance=True)
df.dropna(axis=1,inplace=True)
others = train[train['target'] != 0]
index_values = list(others['target'].unique())

x_train, x_val, y_train, y_val = split(others)

X, y = sampling_strategy("SMOTE")

model_1.fit(X, y, eval_set=(x_val,y_val), verbose=0)
val_pred = model_1.predict(x_val)
evaluate_model(y_val, val_pred, index_values)

#Train
final_train = train.copy()
final_train['prediction'] = model1.predict(final_train[x_train.columns])
print(final_train['prediction'].value_counts())
print('')

one_class = final_train[final_train['prediction'] == 0]
other_class = final_train[final_train['prediction'] != 0]
other_class['prediction'] = model_1.predict(other_class[x_train.columns])
final_train_df = pd.concat([one_class, other_class],axis=0)
evaluate_model(final_train_df['target'], final_train_df['prediction'], [0,1,2,3,4])

#Test
final_test = test.copy()
final_test['prediction'] = model1.predict(final_test[x_train.columns])
print(final_test['prediction'].value_counts())
print('')

one_class = final_test[final_test['prediction'] == 0]
other_class = final_test[final_test['prediction'] != 0]
other_class['prediction'] = model_1.predict(other_class[x_train.columns])
final_test_df = pd.concat([one_class, other_class],axis=0)
evaluate_model(final_test_df['target'], final_test_df['prediction'], [0,1,2,3,4])

"""**(b) Random Forest Classifier -  SMOTE sampling strategy**"""

onevsrest = train.copy()
model2 = RandomForestClassifier(class_weight="balanced")
onevsrest['target'] = np.where(train['target'] == 0, 0, 999)
x_train, x_val, y_train, y_val = split(onevsrest)
index_values = list(onevsrest['target'].unique())

X, y = sampling_strategy("SMOTE")

model2.fit(X, y)
val_pred = model2.predict(x_val)
evaluate_model(y_val, val_pred, index_values)

model_2 = RandomForestClassifier(class_weight="balanced")
df.dropna(axis=1,inplace=True)
others = train[train['target'] != 0]
index_values = list(others['target'].unique())

x_train, x_val, y_train, y_val = split(others)

X, y = sampling_strategy("SMOTE")

model_2.fit(X, y)
val_pred = model_2.predict(x_val)
evaluate_model(y_val, val_pred, index_values)

#Train
final_train = train.copy()
final_train['prediction'] = model2.predict(final_train[x_train.columns])
print(final_train['prediction'].value_counts())
print('')

one_class = final_train[final_train['prediction'] == 0]
other_class = final_train[final_train['prediction'] != 0]
other_class['prediction'] = model_2.predict(other_class[x_train.columns])
final_train_df = pd.concat([one_class, other_class],axis=0)
evaluate_model(final_train_df['target'], final_train_df['prediction'], [0,1,2,3,4])

#Test
final_test = test.copy()
final_test['prediction'] = model2.predict(final_test[x_train.columns])
print(final_test['prediction'].value_counts())
print('')

one_class = final_test[final_test['prediction'] == 0]
other_class = final_test[final_test['prediction'] != 0]
other_class['prediction'] = model_2.predict(other_class[x_train.columns])
final_test_df = pd.concat([one_class, other_class],axis=0)
evaluate_model(final_test_df['target'], final_test_df['prediction'], [0,1,2,3,4])

"""**(c) Catboost Classifier -  SMOTE sampling strategy**"""

onevsrest = train.copy()
model3 = catboost.CatBoostClassifier(n_estimators=2500,random_state=0, learning_rate=0.03, verbose=100, early_stopping_rounds=50,auto_class_weights="Balanced")
onevsrest['target'] = np.where(train['target'] == 0, 0, 999)
x_train, x_val, y_train, y_val = split(onevsrest)
index_values = list(onevsrest['target'].unique())

X, y = sampling_strategy("SMOTE")

model3.fit(X, y, eval_set=(x_val,y_val), verbose=0)
val_pred = model3.predict(x_val)
evaluate_model(y_val, val_pred, index_values)

model_3 = catboost.CatBoostClassifier(n_estimators=2500,random_state=0, learning_rate=0.03, verbose=100, early_stopping_rounds=50,auto_class_weights="Balanced")
df.dropna(axis=1,inplace=True)
others = train[train['target'] != 0]
index_values = list(others['target'].unique())

x_train, x_val, y_train, y_val = split(others)

X, y = sampling_strategy("SMOTE")

model_3.fit(X, y, eval_set=(x_val,y_val), verbose=0)
val_pred = model_3.predict(x_val)
evaluate_model(y_val, val_pred, index_values)

"""# Best Model - Catboost with SMOTE sampling strategy and One-vs-Rest dataset split"""

#Train
final_train = train.copy()
final_train['prediction'] = model3.predict(final_train[x_train.columns])
print(final_train['prediction'].value_counts())
print('')

one_class = final_train[final_train['prediction'] == 0]
other_class = final_train[final_train['prediction'] != 0]
other_class['prediction'] = model_3.predict(other_class[x_train.columns])
final_train_df = pd.concat([one_class, other_class],axis=0)
evaluate_model(final_train_df['target'], final_train_df['prediction'], [0,1,2,3,4])

#Test
final_test = test.copy()
final_test['prediction'] = model3.predict(final_test[x_train.columns])
print(final_test['prediction'].value_counts())
print('')

one_class = final_test[final_test['prediction'] == 0]
other_class = final_test[final_test['prediction'] != 0]
other_class['prediction'] = model_3.predict(other_class[x_train.columns])
final_test_df = pd.concat([one_class, other_class],axis=0)
evaluate_model(final_test_df['target'], final_test_df['prediction'], [0,1,2,3,4])

"""Feature importance"""

pd.Series(model3.feature_importances_, index=x_train.columns).nlargest(10).plot(kind='barh')

pd.Series(model_3.feature_importances_, index=x_train.columns).nlargest(10).plot(kind='barh')